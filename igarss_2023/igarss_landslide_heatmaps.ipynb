{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Landslide Hazard Analysis Using SAR\n",
    "Intro to the use case/methods used"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Search for SLC images over Haiti in a defined time period"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.strptime('2021-05-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "end_time = datetime.strptime('2021-08-16T23:59', '%Y-%m-%dT%H:%M')\n",
    "event_time = datetime.strptime('2021-08-14T00:00', '%Y-%m-%dT%H:%M')\n",
    "\n",
    "import asf_search\n",
    "scenes_to_submit = []\n",
    "wkt = 'POLYGON((-74.6 18.0,-73.0 18.0,-73.0 18.8,-74.6 18.8, -74.6 18.0))'\n",
    "results = asf_search.geo_search(platform=[asf_search.PLATFORM.SENTINEL1], intersectsWith=wkt, processingLevel='SLC', start=start_time, end=end_time)\n",
    "[scenes_to_submit.append(result.properties['sceneName']) for result in results]\n",
    "print(f'There are {len(scenes_to_submit)} scenes in the AOI between {start_time} and {end_time}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Request HyP3 processing of Haiti data for two years"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "\n",
    "print(f'Submitting {len(scenes_to_submit)} jobs')\n",
    "hyp3 = sdk.HyP3()\n",
    "rtc_jobs = sdk.Batch()\n",
    "for scene in scenes_to_submit:\n",
    "    rtc_jobs += hyp3.submit_rtc_job(granule=scene, name='IGARSS-HAITI')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir_path = 'haiti_rtcs'\n",
    "rtc_jobs = hyp3.watch(rtc_jobs)\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "file_list = succeeded_jobs.download_files(location=data_dir_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the staged version of the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "hyp3 = sdk.HyP3()\n",
    "\n",
    "jobs = hyp3.find_jobs(user_id='jrsmale', name='IGARSS-HAITI')\n",
    "\n",
    "data_dir_path = 'haiti_rtcs'\n",
    "months_before = datetime(2021,7,14)\n",
    "dates = [datetime.strptime(job.to_dict()['job_parameters']['granules'][0][33:41], '%Y%m%d') for job in jobs]\n",
    "indexes = [i for i,date in enumerate(dates) if date >= months_before]\n",
    "desired_jobs = sdk.Batch([jobs[i] for i in indexes])\n",
    "if not os.path.isdir(data_dir_path):\n",
    "    os.mkdir(data_dir_path)\n",
    "download_paths = desired_jobs.download_files(location=data_dir_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Crop all images to same extent (e.g. InSAR Notebook)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal\n",
    "\n",
    "def clip_hyp3_products_to_same_extent(data_dir: List[Union[str, Path]]) -> List[str]:\n",
    "    \"\"\"Clip all GeoTIFF hyp3 products to a specified extent\n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        extent:\n",
    "            a list of the upper-left x, upper-left y, lower-right x, and lower-right y corner coordinates of desired extent.\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    for file in data_dir.glob(f'**/*VV.tif'):\n",
    "        dst_file = Path(str(file.absolute()).replace(f'VV.tif', f'VV_clipped.tif'))\n",
    "        gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=extent, projWinSRS=\"EPSG:4326\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extent = [-74.6, 18.8, -73.0, 18.0]\n",
    "clip_hyp3_products_to_same_extent(download_paths, extent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the geotiffs into Xarray with datetime stamps for each image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_tif_names(scene_dir_path):\n",
    "    scene_path_listed = os.listdir(scene_dir_path)\n",
    "    scene_files_vv = [fname for fname in scene_path_listed if fname.endswith('_VV_clipped.tif')]\n",
    "    return scene_files_vv\n",
    "\n",
    "scenes_listed = os.listdir(data_dir_path)\n",
    "fpaths_vv = []\n",
    "\n",
    "for element in range(len(scenes_listed)):\n",
    "    print(f'{data_dir_path}/{scenes_listed[element]}')\n",
    "    try:\n",
    "        good_files = extract_tif_names(f'{data_dir_path}/{scenes_listed[element]}')\n",
    "        fpaths_vv.append(f'{data_dir_path}/{scenes_listed[element]}/{good_files[0]}')\n",
    "    except:\n",
    "        print(f'Couldnt use {scenes_listed[element]}. Skipping.')\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pre-temporal averaging, create time series plot of single pixel (or group of pixels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "def preprocess(da_orig, file_type: str='vv'):\n",
    "    '''function that should return an xarray object with time dimension and associated metadata given a path to a single RTC scene, if its dualpol will have multiple bands, currently just as 2 data arrays but could merge.\n",
    "    goal would be to apply this a list of directories for different RTC products, return cube along time dimension - I think?\n",
    "    - for concatenating, would need to check footprints and only take products with the same footprint, or subset them all to a common AOI? '''\n",
    "    da = da_orig.copy()\n",
    "    da = da.rename({'band_data': file_type}).squeeze()\n",
    "    fname = os.path.basename(da_orig['band_data'].encoding['source'])\n",
    "    date = datetime.strptime(fname[7:22], '%Y%m%dT%H%M%S')\n",
    "    da = da.assign_coords({'acq_date': date})\n",
    "    da = da.expand_dims('acq_date')\n",
    "    da = da.drop_duplicates(dim=['x', 'y'])\n",
    "\n",
    "    return da\n",
    "\n",
    "\n",
    "vv = xr.open_mfdataset(paths = fpaths_vv, preprocess = preprocess, chunks = 'auto', engine='rasterio', data_vars='minimal', coords='minimal', concat_dim='acq_date', combine='nested', parallel=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a temporal average for both pre and post EQ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "date_bins = [start_time, event_time, end_time]\n",
    "date_bin_labels = [\"preevent\", \"postevent\"]\n",
    "\n",
    "vv = vv.groupby_bins(\"acq_date\", date_bins, labels=date_bin_labels)\n",
    "mean_vv = vv.mean(dim='acq_date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform a log difference of the two resulting images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_diff = 10*np.log10(mean_vv['vv'][0]/mean_vv['vv'][1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(log_diff)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discuss options for thresholding the difference image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the COP30 DEM to remove change detections in areas with slopes <5 degrees use gdaldem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dem_stitcher import stitch_dem\n",
    "\n",
    "\n",
    "dem_file = data_dir_path / 'DEM.tif'\n",
    "bounds = [-74.6, 18.0, -73.0, 18.8]\n",
    "X, p = stitch_dem(bounds,\n",
    "                  dem_name='glo_30',  # Global Copernicus 30 meter resolution DEM\n",
    "                  dst_ellipsoidal_height=False,\n",
    "                  dst_area_or_point='Point')\n",
    "\n",
    "import rasterio\n",
    "\n",
    "with rasterio.open(dem_file, 'w', **p) as ds:\n",
    "   ds.write(X, 1)\n",
    "   ds.update_tags(AREA_OR_POINT='Point')\n",
    "\n",
    "process_dem_file = data_dir_path / 'DEM_processed.tif'\n",
    "gdal.DEMProcessing(destName=str(process_dem_file), srcDS=str(dem_file), processing=\"slope\", format=\"Gtiff\", slopeFormat=\"degree\")\n",
    "\n",
    "height, width = np.shape(log_diff)\n",
    "gdal.Warp(str(process_dem_file), str(process_dem_file), dstSRS='EPSG:4326',\n",
    "                  outputBounds=bounds, width=width, height=height, resampleAlg='nearest', format='GTiff')\n",
    "\n",
    "dem = gdal.Open(str(process_dem_file), gdal.GA_ReadOnly).ReadAsArray()\n",
    "dem_mask = dem > 5\n",
    "\n",
    "log_diff = log_diff.where(dem_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Plot a histogram for the difference image (might have to subset histogram source to area with equal amounts of landslides and non-landslides)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(log_diff)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a figure to interactively view the data and set a threshold using matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.matshow(log_diff.where(dem_mask))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}