{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {},
   "source": [
    "# Mt. Edgecumbe volcanic InSAR time series analysis with HyP3 and MintPy\n",
    "\n",
    "In this notebook, you will learn how to perform a time series InSAR analysis using the popular Small BAseline Subset (SBAS) technique. SBAS is well suited for monitoring slow, consistent deformation of the earth's surface caused by processes such as slow landslides, subsidence, fault creep and volcanic inflation. In this tutorial we will focus on a volcanic inflation use case at [Mt. Edgecumbe, Alaska](https://en.wikipedia.org/wiki/Mount_Edgecumbe_(Alaska)).\n",
    "\n",
    "In April 2022, a seismic swarm near Mt. Edgecumbe in southeast Alaska suggested there could be renewed activity at the volcano. However, since the last sign of activity at Mt. Edgecumbe was about 800 years ago, there was no monitoring equipment installed at the volcano. This made it difficult to determine if the seismic swarm was unrelated to volcanic activity, or if the volcano was returning to an active state. Luckily, the team at the Alaska Volcano Observatory (AVO) included experienced InSAR users, and they were able use a time series InSAR analysis to show that volcanic inflation had begun at the site in 2018. This analysis took much less time than more traditional methods, and was critical for providing timely information about the status of the volcano to the neighboring city of Sitka, Alaska.\n",
    "\n",
    "This notebook will show you how to perform the InSAR time series analysis that the AVO team used to reach their conclusions. It follows the methodology detailed in their recent paper [(Grapenthin et al., 2022)](https://doi.org/10.1029/2022GL099464), which utilizes On Demand InSAR products from the Alaska Satellite Facility (ASF) and the MintPy time series analysis software. \n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "<br></br>",
    "1. Use the [HyP3 Python SDK](https://hyp3-docs.asf.alaska.edu/using/sdk/) to:\n",
    "   - Request On Demand InSAR products from ASF HyP3\n",
    "   - Download the InSAR products when they are done processing\n",
    "<br></br>",
    "2. Use [MintPy](https://mintpy.readthedocs.io/en/latest/) and various Python utilities to:\n",
    "   - Download staged data that we will use for the time series (check out the `data_prep.py` script to see how the data was prepared)\n",
    "   - Assess the quality of the interferogram network we will use for the analysis\n",
    "   - Assess whether the data quality is suitable for a time series analysis\n",
    "   - Perform SBAS time series analyses for three InSAR stacks over Mt. Edgecumbe\n",
    "   - Demonstrate how to view the results of a time series analysis\n",
    "   - Reproduce the main InSAR figure from the AVO team's recent publication [(Figure 2 from Grapenthin et al., 2022)](https://doi.org/10.1029/2022GL099464)\n",
    "---\n",
    "\n",
    "**Note:** This notebook uses staged data to ensure that there is adequate time to step through the InSAR time series workflow and discuss the analysis methods. It also assumes that you have some familiarity with InSAR processing already. If you're new to InSAR and working with ASF's on-demand services, you may find the following resources useful:\n",
    "1. ASF's [InSAR On Demand StoryMap](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "2. The `data_prep.py` script in the same directory as this notebook\n",
    "3. [OpenSARlab](https://opensarlab-docs.asf.alaska.edu/)'s highly detailed walkthrough of preparing ASF's On-Demand (HyP3) data for MintPy using these notebooks:\n",
    "    - [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "    - [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "---\n",
    "This notebook and the ones listed above assume that you're working in OpenSARlab. However, you can also run these \n",
    "notebooks outside of OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml) and launching these notebooks from within this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6e353",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need to be in the `insar_analysis` conda environment within OpenSARLab.\n",
    "\n",
    "Alternatively, you can set up your own environment by running these commands in your shell (you'll need to have [conda](https://docs.conda.io/projects/continuumio-conda/en/latest/user-guide/install/index.html) installed):\n",
    "```shell\n",
    "curl -OL https://raw.githubusercontent.com/ASFOpenSARlab/opensarlab-envs/main/Environment_Configs/insar_analysis_env.yml\n",
    "conda env create -f insar_analysis_env.yml\n",
    "```\n",
    "Then launch this notebook from the new environment:\n",
    "```shell\n",
    "conda activate insar_analysis\n",
    "jupyter lab igarss_mtedgecumbe_ts_analysis.ipynb\n",
    "```\n",
    "\n",
    "Once you have completed the setup for one of these two environments, you are ready to start working with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5b0b",
   "metadata": {},
   "source": [
    "## 1. Request On Demand InSAR products from ASF HyP3\n",
    "\n",
    "A major step towards working with SAR data at scale is learning how to request and download data programmatically. Accomplishing these tasks via code makes it much easier to request large quantities of data and to make similar requests in the future.\n",
    "\n",
    "To request the generation of an Interferometric Synthetic Aperture Radar (InSAR) product from ASF, you can follow the general steps outlined in the cells below. For this example, we'll be requesting the generation of an interferogram that shows inflation-related displacement at Mt. Edgecumbe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd24a07-2665-4bdc-83e0-bedc4f33c7fe",
   "metadata": {},
   "source": [
    "1. **Create an account**: If you don't already have NASA Earthdata Login credentials, create a [NASA Earthdata login](https://urs.earthdata.nasa.gov/) profile. This will allow you connect to ASF HyP3 via the Python SDK. Running the cell below will prompt you for your Earthdata username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "hyp3 = sdk.HyP3(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387a5e2-f145-41b8-8cb8-f8d29155fff0",
   "metadata": {},
   "source": [
    "2. **Select your data**: Use ASF's [Vertex](https://search.asf.alaska.edu/) data search portal to find Sentinel-1 scenes you would like to process. For this tutorial, we will use the following scene pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d2ebe-e14e-4998-a37e-f9b32d106902",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = 'S1B_IW_SLC__1SDV_20180628T151540_20180628T151607_011575_015476_4673'\n",
    "secondary = 'S1B_IW_SLC__1SDV_20190705T151547_20190705T151614_017000_01FFC4_D62F'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b4574-0bcd-4ce7-8bda-cc2bb95f17ee",
   "metadata": {},
   "source": [
    "3. **Define your processing parameters**: Determine the specific processing parameters for your InSAR product. This includes selecting the number of looks (which determines the pixel spacing of the output product), and whether to apply a water mask before phase unwrapping. If you are using the InSAR products for MintPy analysis, you will also need to include the DEM and look vector products with your output product. You can read more about the available parameters within the [HyP3 SDK documentation](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_insar_job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa37d6-ec58-4209-bd7d-43b42fd3c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "looks='20x4'\n",
    "include_dem=True\n",
    "include_look_vectors=True\n",
    "apply_water_mask=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427de656-ef70-45d1-b0be-ee63375182ad",
   "metadata": {},
   "source": [
    "4. **Submit a processing request**: Once you have defined your parameters, use the HyP3 SDK's [`submit_insar_job`](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_insar_job) function to submit a processing request. You can use the `project_name` name argument to group sets of requests together under one name so that you can easily look them up later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9930b-1999-4415-a448-a2bbf586a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "project_name = 'edgecumbe_example'\n",
    "jobs = sdk.Batch()\n",
    "jobs += hyp3.submit_insar_job(reference, secondary, name=project_name, \n",
    "                              looks=looks, include_dem=include_dem, include_look_vectors=include_look_vectors, apply_water_mask=apply_water_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d74f02-1225-47ce-bdcc-5a150d16fec3",
   "metadata": {},
   "source": [
    "5. **Monitor the processing status**: After submitting your request, ASF will process your data using HyP3, and output an InSAR product. You can monitor the status of your request by calling the [`watch`](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.watch) HyP3 SDK method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b82d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.watch(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c01d37-7dd6-44f9-b73a-b51bb252dd2c",
   "metadata": {},
   "source": [
    "6. **Access and download the InSAR product**: Once processing is complete, your InSAR job status will be updated to `SUCCEEDED` and your data will be ready to download. You can download the data by searching for jobs using your project name and the `SUCCEEDED` status code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.find_jobs(name=project_name, status_code = 'SUCCEEDED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44506c24-1562-4e2b-87ea-a68bb1c25cb2",
   "metadata": {},
   "source": [
    "...then using the `download_files` method to download the data. The HyP3 SDK also includes an `extract_zipped_product` utility that you can use to unzip the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b461cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "insar_products = jobs.download_files('.')\n",
    "insar_products = [sdk.util.extract_zipped_product(ii) for ii in insar_products]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad79f1c-96ec-4f99-ae77-328eb07a11d7",
   "metadata": {},
   "source": [
    "Now that we've requested and downloaded the interferogram, let's take a look at it. Here we plot the unwrapped interferogram overlaid on the DEM used for processing. This interferogram shows the inflation deformation signal that Grapenthin et al. originally discovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b21301-3ec9-46b2-87fb-3563ba7e66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unwrapped_file = 'S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722/S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722_unw_phase.tif'\n",
    "amp_file = 'S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722/S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722_amp.tif'\n",
    "\n",
    "ds = gdal.Open(unwrapped_file)\n",
    "unwrapped = np.ma.masked_equal(ds.GetRasterBand(1).ReadAsArray(), 0)\n",
    "del ds\n",
    "\n",
    "ds = gdal.Open(amp_file)\n",
    "amp = np.ma.masked_equal(ds.GetRasterBand(1).ReadAsArray(), 0)\n",
    "del ds\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "ax.imshow(unwrapped[1250:1575, 700:1000], alpha=0.75, cmap='jet')\n",
    "ax.imshow(amp[1250:1575, 700:1000], alpha=0.4, cmap='Greys', norm=matplotlib.colors.LogNorm())\n",
    "ax.set_title('Unwrapped Interferogram')\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17efa6-3371-425a-bcb9-49cafece2bb6",
   "metadata": {},
   "source": [
    "We have now gone through the process of requesting and downloading a single interferogram, but time series InSAR workflows routinely make use of hundreds of interferograms (Grapenthin et al., 2022 used more than a thousand!). We don't have time to request and download this many interferograms during this workshop, so instead we've pre-generated and prepped some InSAR products for you to work with. Think of it as your very own InSAR cooking show!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181031f",
   "metadata": {},
   "source": [
    "## 3. Time-series Analysis with MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7828894-2c7f-479e-82ae-c54f3638830e",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this analyis, we are using InSAR pair lists sourced from the [supplementary information](https://zenodo.org/record/7151431) published by Grapenthin et al.. As mentioned in the section above, we do not have enough time in this workshop to download and create all of the InSAR stacks, so we have done this for you.\n",
    "\n",
    "To prep the data we have:\n",
    "\n",
    "1. Parsed Grapenthin et al.'s [supplementary information](https://zenodo.org/record/7151431) file to grab a list of all the InSAR pairs we want to process\n",
    "2. Grouped these InSAR pairs into three data stacks which each have a unique orbit direction, path, and frame combination, and submitted each stack for processing via HyP3. We've also submitted a fourth stack that will help us explore the effect of water masking\n",
    "3. Downloaded the resulting interferogram files\n",
    "4. Clipped all input data to an area of interest where all the interferograms have valid data (See section 3.1 of our [basic MintPy notebook](https://nbviewer.org/github/ASFHyP3/hyp3-docs/blob/main/docs/tutorials/hyp3_insar_stack_for_ts_analysis.ipynb))\n",
    "5. Loaded a subset of the data surrounding Mt. Edgecumbe into MintPy by running MintPy's initial `load_data` step\n",
    "\n",
    "Take a look at the `prep_data.py` script in the same directory as this notebook for the details on how we prepared the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdc929-1c7a-473b-93d3-0b304072a8df",
   "metadata": {},
   "source": [
    "### 3.1 Download the Staged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a2a5e-1463-48f2-ba37-aad39b48def6",
   "metadata": {},
   "source": [
    "Let's go ahead and download the staged data from Amazon Web Services cloud storage solution, the Simple Storage Service (S3). This cell will download the data from S3, then unzip it into your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74467d63-2961-4d64-b9e8-dfadd6875ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "files = ['ascending_50.zip', 'ascending_79.zip', 'descending_174.zip', 'descending_174_nomask.zip']\n",
    "\n",
    "for file in files:\n",
    "    download_path = Path(file)\n",
    "    s3_client.download_file('ffwilliams2-shenanigans', f'igarss_2023/{file}', download_path)\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(download_path.stem)\n",
    "    os.unlink(download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1eb17-d324-40cf-b276-119defcda838",
   "metadata": {},
   "source": [
    "### 3.2 MintPy Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ce31d-2276-4336-8e93-569a033f43b1",
   "metadata": {},
   "source": [
    "The main interface for MintPy is the command line interface (CLI) tool `smallbaselineApp.py`, which you can call from this notebook or in your terminal. Whenever you begin working with a new CLI tool, it's a good idea to read the introductory documentation for the tool. This will save a ton of headaches in the long run! MintPy's documentation can be found on its [GitHub page](https://github.com/insarlab/MintPy), or by calling the tool with the `--help` flag (see below). Most Python CLI tools have a `--help` option, so get in the habit of using it whenever you begin working with a new tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd69717-b132-42a7-a7f1-3d77a8b2ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feae62f-32a8-4487-a581-717115353828",
   "metadata": {},
   "source": [
    "MintPy has a ton of configuration options that we will use to produce the best analysis that we can, and to replicate the workflow of Grapenthin et al.. We'll be using the defaults for many of MintPy's settings (you can see all of MintPy's defaults by running the command `smallbaselineApp.py -H`), but we will set some key settings ourselves. Run the command below to view the settings for one of our InSAR stacks. Other than the data loading options, we use the same settings for all stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df6393-ce66-445c-bf63-5cd5620c9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat descending_174/mintpy_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dc2942-981a-4a52-9b3c-2672aa3a90dc",
   "metadata": {},
   "source": [
    "The settings can be broken down into six groups: input data options, geographic options, inteferogram network options, unwrapping error correction options, tropospheric correction options, and topographic residual correction options:\n",
    "\n",
    "1. **Input Data Options:**\n",
    "    - The settings in the first three sections (processor, interferogram datasets, and geometry datasets) tell MintPy which InSAR processor we used to create our data, and where to find various datasets it needs for processing.\n",
    "2. **Geographic Options:**\n",
    "    -  The next section gives MintPy some geographic information. It tells MintPy to only load a subset of the data surrounding Mt. Edgecumbe, and to use the point `6330696, 456350` as the reference point for the time series velocity calculation. Both of these options are specified in the geographic projection of the input data, which in this case is UTM zone 8N (EPSG:32608).\n",
    "3. **Interferogram Network Options:**\n",
    "    - An important addage to remember when conducting InSAR analyses is *\"garbage in, garbage out\"*. If you include poor quality (highly-decorrelated) interferograms in your analysis, they will lead to poor results that are difficult to interpret. For this reason, we exclude any interferograms that have an average coherence less than `0.7`. **THIS IS THE MOST IMPORTANT PARAMETER YOU WILL SET WHEN USING MINTPY!!!** Take the time to make sure this value is right for your use case. In addition, MintPy gives you the option to remove individual problematic interferograms using the `mintpy.network.excludeIfgIndex` option. In most cases it's worth taking the time to go through each interferogram individually and remove any that have obvious decorrelation or unwrapping issues.\n",
    "4. **Unwrapping Error Correction Options:**\n",
    "    - Unwrapping error correction uses phase closure trends to reduce the number of unwrapping errors in the input data (read more [here](https://doi.org/10.1016/j.cageo.2019.104331)) and is turned on by default. Unfortunately HyP3 is not compatible with this step because it does not produce some of the needed input data, so we will be skipping this correction.\n",
    "5. **Tropospheric Phase Correction Options:**\n",
    "    - SAR signals propogate through the troposphere at slightly different rates depending on atmospheric conditions, which can lead to troposphere-related signasl in interferograms that we need to correct. You can learn more about this error source [here](https://doi.org/10.1016/j.earscirev.2019.03.008). Most troposphere correction algorithms utilize external atmospheric data to predict the error caused by this effect, then correct for it. In this case, we're using the [PyAPS](https://github.com/insarlab/PyAPS) Python package in conjunction with [ERA5](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) data to perform this correction. \n",
    "6. **Topographic Residual Correction Options:**\n",
    "    - Errors in the DEMs used for InSAR processing can lead to errors that are proportional to the perpendicular baseline of the InSAR pair. This is another effect that is important to correct for. MintPy uses the method proposed by [Heresh and Amelung, 2013](https://doi.org/10.1109/TGRS.2012.2227761) to perform this correction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8546c7c-c9e1-47e7-91e7-446b0ef58e63",
   "metadata": {},
   "source": [
    "### 3.3 Run MintPy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df4f46-e91a-4d04-a522-c832ff6fe4e7",
   "metadata": {},
   "source": [
    "Now that we've covered the basics of our MintPy configuration, it's time to perform our analysis! As mentioned, above we will be processing data from four stacks, so you'll need to run the section of code starting at section 3.3 (here) to just before section 4 four times. Once for each data stack. Make sure to run each stack in order by modifying the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9b16a-f0d1-4594-b1c6-7a9c56abe601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you run MintPy for all four stacks\n",
    "stacks = ['ascending_50', 'ascending_79', 'descending_174', 'descending_174_nomask']\n",
    "stack = stacks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aaf24-7662-4928-af7a-fcaecdd93dde",
   "metadata": {},
   "source": [
    "#### 3.3.1 Check Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d3cf2-f0c5-45ee-aecb-4397b040c140",
   "metadata": {},
   "source": [
    "As we mentioned before, selecting the right interferogram network is the most important way to ensure a high quality time series InSAR analysis. Because of this, we're going to look at various ways you can analyze the quality of your interferogram network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e60df-a4b7-47b1-a713-17422a521595",
   "metadata": {},
   "source": [
    "##### 3.3.1.1 Network Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcfe7b-951e-448e-8fa0-1f807712d9b7",
   "metadata": {},
   "source": [
    "The first thing to check is that you have a fully connected network (e.g., every date in your analysis window is covered by at least one interferogram). This can be a challenge to ensure sometimes due to seasonal decorrelation issues. In snowy areas like Mt. Edgecumbe, the presence of snow on the ground introduces significant decorrelation effects that hinder the accurate measurement of surface displacements. As a result, interferograms generated during winter periods tend to be unreliable. To overcome this challenge, it becomes necessary to exclude interferograms from the winter season. However, excluding winter interferograms leaves a data gap that can hamper your connectivity. To address this issue, you can create longer baseline interferograms, which span a longer period of time and cover the missing winter period. By including a few inteferograms with long temporal baselines, you can ensure connectivity while also not including any highly decorrelated interferograms. See the graph below to see the network that Grapenthin et al. used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d0a40-351a-40d5-8fe0-15d8c83e64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.collections import LineCollection\n",
    "from mintpy.utils.network import get_date12_list\n",
    "\n",
    "pair_list = pd.DataFrame([pair.split('_') for pair in get_date12_list(f'{stack}/inputs/ifgramStack.h5')], columns=['date1', 'date2'])\n",
    "pair_list['date1'] = pd.to_datetime(pair_list['date1'])\n",
    "pair_list['date2'] = pd.to_datetime(pair_list['date2'])\n",
    "\n",
    "# subplot 1 data\n",
    "lines = []\n",
    "bridges = []\n",
    "for i, row in pair_list.iterrows():\n",
    "    point1 = [mdates.date2num(row['date1']), i]\n",
    "    point2 = [mdates.date2num(row['date2']), i]\n",
    "    if point2[0] - point1[0] > 48:\n",
    "        bridges.append([point1, point2])\n",
    "    else:\n",
    "        lines.append([point1, point2])\n",
    "\n",
    "# subplot 2 data\n",
    "date1_number = mdates.date2num(pair_list.date1)\n",
    "date2_number = mdates.date2num(pair_list.date2)\n",
    "dates = np.concatenate((date1_number, date2_number))\n",
    "min_date = np.min(dates)\n",
    "max_date = np.max(dates)\n",
    "\n",
    "date_range = np.arange(np.min(dates), np.max(dates))\n",
    "coverage = np.zeros(int(np.max(dates) - np.min(dates)))\n",
    "for ifg_date1, ifg_date2 in zip(date1_number, date2_number):\n",
    "    ifg_coverage = np.arange(ifg_date1 - min_date, ifg_date2 - min_date, dtype=int)\n",
    "    coverage[ifg_coverage] += 1\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "line_segments = LineCollection(lines, array=range(len(lines)), linewidths=1, cmap='gist_rainbow', label='Interferograms')\n",
    "bridge_segments = LineCollection(bridges, color='black', linestyle='dashed', linewidths=1, label='Bridging Interferograms')\n",
    "ax1.add_collection(line_segments)\n",
    "ax1.add_collection(bridge_segments)\n",
    "ax1.set(\n",
    "    ylabel='Interferogram Number',\n",
    "    xlabel='Date',\n",
    "    xlim=(mdates.date2num(np.min(pair_list['date1'])) - 10, mdates.date2num(np.max(pair_list['date2'])) + 10),\n",
    "    ylim=(-1, pair_list.shape[0] + 1),\n",
    ")\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2.plot(date_range, coverage, color='black', linewidth=2)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "ax2.set(xlabel='Date', ylabel='# of interferograms covering date', ylim=(0, np.max(coverage) + 1))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f428b9b-f494-4df2-9f06-56b3610aaf4c",
   "metadata": {},
   "source": [
    "Each line in the top graph represents an interferogram. You can see that most interferograms span a relatively small date window, but that there are a few long temporal baseline interferograms that span the winter snow season. The bottom graph is a histogram displaying how many interferograms cover each date. As you can see, we have at least one interferogram for each date, so our network is fully connected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b71dcf-19fc-4d6f-9f38-247f6ec4997e",
   "metadata": {},
   "source": [
    "##### 3.3.1.2 Network Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7318e24-3a07-4b43-964a-c1b1e820d016",
   "metadata": {},
   "source": [
    "The next thing we want to consider is network quality. Setting an average coherence threshold of `0.7` already excludes a lot of interferograms (the interferograms whose numbers are red in the graph below are excluded), but there are still some we could consider removing to avoid including interferograms with unwrapping errors. For instance take a look at interferogram number 12 in the `ascending_50` stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4681b1-ba71-44a2-91fc-d1fcb91e3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mintpy.cli import view\n",
    "view.main(f'ascending_50/inputs/ifgramStack.h5 --noverbose'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9354e4d-cbbc-468a-bb5b-7efb6c80584a",
   "metadata": {},
   "source": [
    "If we wanted to remove this interferogram we could run MintPy's `modify_network.py` utility as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a6e7d-cf3e-40e8-93dd-9bbb59da9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !modify_network.py {stack}/inputs/ifgramStack.h5 --exclude-ifg-index 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9b37c-9d7a-4046-811e-a747d2a89054",
   "metadata": {},
   "source": [
    "Then, if we wanted to reset our network for any reason, we could use this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c76bf-8359-4bfc-94a5-8e8cfc0725cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !modify_network.py {stack}/inputs/ifgramStack.h5 --reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fbb9f6-89b4-46ff-a41e-536951c1cbc2",
   "metadata": {},
   "source": [
    "##### 3.3.1.3 View final network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25456fce-d10e-4e02-ac7a-7a4abb35f240",
   "metadata": {},
   "source": [
    "Now that we've made all of our modifications, let's run `smallbaselineApp.py`'s `modify_network` step and view the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e756304-f75b-4430-8d8e-988f56070fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --dostep modify_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e77538-bd5d-40de-b2a4-d10c3f7b5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import plot_network\n",
    "\n",
    "plot_network.main(f'{stack}/inputs/ifgramStack.h5 --figsize 12 3'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738761b-e5cf-43ac-aad4-0a4094c07762",
   "metadata": {},
   "source": [
    "#### 3.3.2 Check Reference Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca3fb9-fddf-44de-a8ac-4f7f11822398",
   "metadata": {},
   "source": [
    "The next important thing to check is that we've selected an appropriate reference point. Since all deformation in our time series will be relative to this point, it is very important that this point is highly coherent and is in a non-deforming location. Note that if you are using multiple co-located stacks (like we are) you should use the same reference point for all stacks. First, we need to run the `reference_point` step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245b6c8-16ec-4000-b516-3aea7379edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --dostep reference_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1ff6e-9df0-4a58-b616-57e627f55751",
   "metadata": {},
   "source": [
    "Then we can view the location of the reference point on top of the average spatial coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e45402-23fe-4d68-8fc2-5b2c0821ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import view\n",
    "from mintpy.utils import readfile\n",
    "\n",
    "cfg = readfile.read_template(f'{stack}/smallbaselineApp.cfg')\n",
    "ref_la, ref_lo = [int(coord) for coord in cfg['mintpy.reference.lalo'].strip(\"[]\").split(', ')]\n",
    "view.main(f'{stack}/avgSpatialCoh.h5 --pts-lalo {ref_la} {ref_lo} --noverbose --figsize 8 8'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1abd4-f3d1-4844-be57-6e2bd85cf11a",
   "metadata": {},
   "source": [
    "By zooming in on this plot, we can see that our reference point has a coherence value of 0.8 - that should be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7ca34-ba99-4e2f-82e4-8535b1c1e24e",
   "metadata": {},
   "source": [
    "#### 3.3.3 Estimate Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd85843-b614-487c-b4ad-969e5b660296",
   "metadata": {},
   "source": [
    "Having checked that our network and reference point are good, we will run the remainder of the analysis. This includes performing the time series inversion, the tropospheric correction, and the topographic residual correction. If you want to read more about MintPy's SBAS workflow, you can read the paper describing the MintPy workflow [here](https://doi.org/10.1016/j.cageo.2019.104331)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33793550-0d53-40e8-9fd1-bced203da9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --start quick_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f94fe95-cd16-4bbb-bc5a-796ad587d81c",
   "metadata": {},
   "source": [
    "Congrats - you have successfully completed a time series InSAR analysis! Use the interactive plot below to view Mt. Edgecumbe's deformation history at specific locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953be71b-2e08-4a84-a47b-6d425c6a01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import tsview\n",
    "\n",
    "cmd = f'{stack}/timeseries_ERA5_demErr.h5 --figsize 9 3 --noverbose'\n",
    "tsview.main(cmd.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e83b0-7128-45af-bf54-7c1d325dd148",
   "metadata": {},
   "source": [
    "**Remember to run MintPy for all four stacks before moving on!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac85337-6096-412b-bfa6-a7616c67f9d6",
   "metadata": {},
   "source": [
    "## 4. Data Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa45e3-72e4-4ca5-9705-05409f90b8dc",
   "metadata": {},
   "source": [
    "Now that you have **run MintPy for all four stacks**, let's take a look at the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a657df-0ac4-44f1-8af0-8b28adc53641",
   "metadata": {},
   "source": [
    "### 4.1 Effect of Water Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d078c0c-e13f-4a42-8bec-192e791c25d9",
   "metadata": {},
   "source": [
    "The first thing that we will take a look at is a real problem that Grapenthin et al. had to troubleshoot when they were getting ready to publish their analysis. In the first version of their analysis, the water mask option HyP3 provided did not mask the water within 100 meters of the land surface. Even this relatively small amount of water present in the scene led to an area of erroneous subsidence northeast Mt. Edgecumbe. The HyP3 team has now tightened their water mask so that it follows the coastline closely, but we can re-create this issue by comparing the water masked and non water masked versions of our descending track stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647b87c-aca7-4319-9165-a9965d5eaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mintpy.utils import readfile\n",
    "\n",
    "velocity_nomask, _ = readfile.read('descending_174_nomask/velocity.h5')\n",
    "velocity_nomask = np.ma.masked_equal(velocity_nomask,0)\n",
    "\n",
    "velocity_mask, _ = readfile.read('descending_174/velocity.h5')\n",
    "velocity_mask = np.ma.masked_equal(velocity_mask,0)\n",
    "\n",
    "difference = velocity_mask - velocity_nomask\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 6))\n",
    "ax1.imshow(velocity_mask, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax1.set(title='Water Masked')\n",
    "ax2.imshow(velocity_nomask, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax2.set(title='Not Water Masked')\n",
    "diff_plot = ax3.imshow(difference, cmap='jet', norm=colors.CenteredNorm(halfrange=np.std(difference)))\n",
    "ax3.set(title='Water Masked - Not Water Masked')\n",
    "\n",
    "cax = ax3.inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "f.colorbar(diff_plot, ax=ax3, cax=cax)\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00f602-b2b5-41c8-a78c-59991ffa552d",
   "metadata": {},
   "source": [
    "### 4.2 Final Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb8005-4549-4695-ac4a-bc9c9af3d5fc",
   "metadata": {},
   "source": [
    "Finally, let's put it all together. Using the final velocity files from each stack (except the descending stack that did not have water masking applied), we can recreate the main portion of [Figure 2 from Grapenthin et al., 2022](https://doi.org/10.1029/2022GL099464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e3180-c306-4bfd-88c2-2639657440ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mintpy.utils import readfile\n",
    "\n",
    "ascending_50, _ = readfile.read('ascending_50/velocity.h5')\n",
    "ascending_50 = np.ma.masked_equal(ascending_50, 0)\n",
    "\n",
    "ascending_79, _ = readfile.read('ascending_79/velocity.h5')\n",
    "ascending_79 = np.ma.masked_equal(ascending_79, 0)\n",
    "\n",
    "descending_174, _ = readfile.read('descending_174/velocity.h5')\n",
    "descending_174 = np.ma.masked_equal(descending_174, 0)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 6))\n",
    "ax1.imshow(ascending_79, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax1.set(title='Ascending 79')\n",
    "ax2.imshow(ascending_50, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax2.set(title='Ascending 50')\n",
    "cbar_plot = ax3.imshow(descending_174, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax3.set(title='Descending 174')\n",
    "\n",
    "cax = ax3.inset_axes([1.05, 0.25, 0.05, 0.5])\n",
    "f.colorbar(cbar_plot, ax=ax3, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10329f4d-4ce5-48ea-9b32-8d0e269cc9cd",
   "metadata": {},
   "source": [
    "CONGRATULATIONS - you have just performed a publication-quality time series InSAR analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98acaf7-a08e-4db0-acc9-ca0bbdda609e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
