{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Landslide Hazard Analysis Using SAR\n",
    "Intro to the use case/methods used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Search for SLC images over Haiti in a defined time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# start_time = datetime.strptime('2021-05-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "start_time = datetime.strptime('2020-08-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "end_time = datetime.strptime('2021-08-16T23:59', '%Y-%m-%dT%H:%M')\n",
    "event_time = datetime.strptime('2021-08-14T00:00', '%Y-%m-%dT%H:%M')\n",
    "\n",
    "import asf_search\n",
    "scenes_to_submit = []\n",
    "wkt = 'POLYGON((-74.6 18.0,-73.0 18.0,-73.0 18.8,-74.6 18.8, -74.6 18.0))'\n",
    "results_descending = asf_search.geo_search(platform=[asf_search.PLATFORM.SENTINEL1], intersectsWith=wkt, processingLevel='SLC', start=start_time, end=end_time, relativeOrbit=142, frame=530)\n",
    "# [scenes_to_submit.append(result.properties['sceneName']) for result in results]\n",
    "# print(f'There are {len(scenes_to_submit)} scenes in the AOI between {start_time} and {end_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Request HyP3 processing of Haiti data for two years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "properties = [result.geojson()['properties'] for result in results_descending]\n",
    "geometries = [shape(result.geojson()['geometry']) for result in results_descending]\n",
    "gdf = gpd.GeoDataFrame(properties, geometry=geometries,crs='EPSG:4326')\n",
    "scenes_to_submit = list(gdf['sceneName'])\n",
    "print(gdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.explore(style_kwds=dict(color='black', fill=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_gdf = gdf[['sceneName', 'startTime']].copy()\n",
    "plot_gdf['startTime'] = pd.to_datetime(plot_gdf['startTime'])\n",
    "plot_gdf = plot_gdf.sort_values('startTime').reset_index()\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(7,7))\n",
    "ax.scatter(pd.to_datetime(plot_gdf['startTime']), plot_gdf.index, s=5)\n",
    "ax.set(xlabel='Date', ylabel='Image Number')\n",
    "ax.axvline(event_time, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "\n",
    "print(f'Submitting {len(scenes_to_submit)} jobs')\n",
    "hyp3 = sdk.HyP3()\n",
    "rtc_jobs = sdk.Batch()\n",
    "for scene in scenes_to_submit:\n",
    "    rtc_jobs += hyp3.submit_rtc_job(granule=scene, name='IGARSS-HAITI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir_path = 'haiti_rtcs'\n",
    "rtc_jobs = hyp3.watch(rtc_jobs)\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "file_list = succeeded_jobs.download_files(location=data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "hyp3 = sdk.HyP3()\n",
    "\n",
    "if not os.path.isdir('haiti_rtcs'):\n",
    "    os.mkdir('haiti_rtcs')\n",
    "rtc_jobs = hyp3.find_jobs(name='IGARSS-HAITI', user_id ='ffwilliams2')\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "file_list = succeeded_jobs.download_files(location='haiti_rtcs')\n",
    "\n",
    "files = Path('haiti_rtcs').glob('*')\n",
    "for file in files:\n",
    "    sdk.util.extract_zipped_product(file, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop all images to same extent (e.g. InSAR Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "def clip_hyp3_products_to_common_overlap(data_dir: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    files_for_mintpy = ['_VV.tif', '_VH.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "\n",
    "        for file in data_dir.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('haiti_rtcs')\n",
    "files = list(data_dir.glob('**/*_VV.tif'))\n",
    "overlap = get_common_overlap(files)\n",
    "clip_hyp3_products_to_common_overlap(data_dir, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the geotiffs into Xarray with datetime stamps for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pre-temporal averaging, create time series plot of single pixel (or group of pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess(da_orig, file_type: str='vv'):\n",
    "    '''function that should return an xarray object with time dimension and associated metadata given a path to a single RTC scene, if its dualpol will have multiple bands, currently just as 2 data arrays but could merge.\n",
    "    goal would be to apply this a list of directories for different RTC products, return cube along time dimension - I think?\n",
    "    - for concatenating, would need to check footprints and only take products with the same footprint, or subset them all to a common AOI? '''\n",
    "    da = da_orig.copy()\n",
    "    da = da.rename({'band_data': file_type}).squeeze()\n",
    "    fname = os.path.basename(da_orig['band_data'].encoding['source'])\n",
    "    time = datetime.strptime(fname[7:22], '%Y%m%dT%H%M%S')\n",
    "    da = da.assign_coords({'time': time})\n",
    "    da = da.expand_dims('time')\n",
    "    da = da.drop_duplicates(dim=['x', 'y'])\n",
    "\n",
    "    return da\n",
    "\n",
    "fpaths_vv = list(Path('haiti_rtcs').glob('*/*_VV_clipped.tif'))\n",
    "rtc_vv = xr.open_mfdataset(paths = fpaths_vv, preprocess = preprocess, chunks = 'auto', engine='rasterio', data_vars='minimal', coords='minimal', concat_dim='time', combine='nested', parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_vv['vv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pre-temporal averaging, create time series plot of single pixel (or group of pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a temporal average for both pre and post EQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.strptime('2020-08-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "end_time = datetime.strptime('2021-08-16T23:59', '%Y-%m-%dT%H:%M')\n",
    "event_time = datetime.strptime('2021-08-14T00:00', '%Y-%m-%dT%H:%M')\n",
    "\n",
    "date_bins = [start_time, event_time, end_time]\n",
    "date_bin_labels = ['preevent', 'postevent']\n",
    "\n",
    "rtc_vv = rtc_vv.groupby_bins('time', date_bins, labels=date_bin_labels)\n",
    "mean_vv = rtc_vv.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vv['vv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Perform a log difference of the two resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_diff =  10*np.log10(mean_vv['vv'][0]/mean_vv['vv'][1])\n",
    "log_diff = log_diff.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(log_diff)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Discuss options for thresholding the difference image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use the COP30 DEM to remove change detections in areas with slopes <5 degrees use gdaldem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dem_stitcher import stitch_dem\n",
    "\n",
    "\n",
    "dem_file = data_dir_path / 'DEM.tif'\n",
    "bounds = [-74.6, 18.0, -73.0, 18.8]\n",
    "X, p = stitch_dem(bounds,\n",
    "                  dem_name='glo_30',  # Global Copernicus 30 meter resolution DEM\n",
    "                  dst_ellipsoidal_height=False,\n",
    "                  dst_area_or_point='Point')\n",
    "\n",
    "import rasterio\n",
    "\n",
    "with rasterio.open(dem_file, 'w', **p) as ds:\n",
    "   ds.write(X, 1)\n",
    "   ds.update_tags(AREA_OR_POINT='Point')\n",
    "\n",
    "process_dem_file = data_dir_path / 'DEM_processed.tif'\n",
    "gdal.DEMProcessing(destName=str(process_dem_file), srcDS=str(dem_file), processing=\"slope\", format=\"Gtiff\", slopeFormat=\"degree\")\n",
    "\n",
    "height, width = np.shape(log_diff)\n",
    "gdal.Warp(str(process_dem_file), str(process_dem_file), dstSRS='EPSG:4326',\n",
    "                  outputBounds=bounds, width=width, height=height, resampleAlg='nearest', format='GTiff')\n",
    "\n",
    "dem = gdal.Open(str(process_dem_file), gdal.GA_ReadOnly).ReadAsArray()\n",
    "dem_mask = dem > 5\n",
    "\n",
    "log_diff = log_diff.where(dem_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " Plot a histogram for the difference image (might have to subset histogram source to area with equal amounts of landslides and non-landslides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(log_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a figure to interactively view the data and set a threshold using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(log_diff.where(dem_mask))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar_analysis [conda env:.local-insar_analysis]",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
