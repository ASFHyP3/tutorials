{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Landslide Hazard Analysis Using SAR\n",
    "In this notebook, you will learn how to generate a landslide density map  with RTC-based change detection analysis.  You will create multi-temporal stacks of Sentinel-1 data using [XArray](https://docs.xarray.dev/en/stable/) and compare data from before and after an earthquake that triggered landslides.\n",
    "\n",
    "In this tutorial, we will focus mapping landslides triggered by an $M_w$ 7.2 [earthquake in Haiti](https://en.wikipedia.org/wiki/2021_Haiti_earthquake) that occurred on August 14, 2021. The earthquake triggered widespread landslides across the southwestern part of the country, with  least 8,444 landslides triggered across a 2,700 $km^2$ (1,000 sq mi) area [(Zhang et al., 2021)](https://www.sciencedirect.com/science/article/abs/pii/S0169555X22003129).  Rapid response to the landslide and inventory of landslides was further hindered by the arrival of Tropical Storm Grace. The presence of consistent cloud coverage makes SAR data an ideal candidate to detect landslides in the aftermath, since SAR can penetrate through cloud cover.\n",
    "\n",
    "This notebook will show you how to perform the time-series change detection as performed by [Handwerger et al., 2022](https://nhess.copernicus.org/articles/22/753/2022/). This process utilizes OnDemand RTC products from the Alaska Satellite Facility.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Use the HyP3 Python SDK to:\n",
    "   - Request On Demand RTC products from ASF HyP3\n",
    "   - Download the RTC products when they are done processing\n",
    "<br></br>\n",
    "2. And you will use [Xarray](https://docs.xarray.dev/en/stable/) and various Python utilities to:\n",
    "   - Download pre-processed data that we will use for the time series\n",
    "   - Load data with Xarray\n",
    "   - Group data pre-event and post-event and average both stacks\n",
    "   - Perform a log difference between pre-event and post-even scenes\n",
    "   - Plot a histogram of the log difference for a subset of the area\n",
    "   - Reproduce the main landslide heatmap figure from Handwerger et al., 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need to be in the `insar_analysis` conda environment within OpenSARLab.\n",
    "\n",
    "Alternatively, you can set up your own environment by running these commands in your shell (you'll need to have [conda](https://docs.conda.io/projects/continuumio-conda/en/latest/user-guide/install/index.html) installed):\n",
    "```shell\n",
    "curl -OL https://raw.githubusercontent.com/ASFOpenSARlab/opensarlab-envs/main/Environment_Configs/insar_analysis_env.yml\n",
    "conda env create -f insar_analysis_env.yml\n",
    "```\n",
    "Then launch this notebook from the new environment:\n",
    "```shell\n",
    "conda activate insar_analysis\n",
    "jupyter lab igarss_mtedgecumbe_ts_analysis.ipynb\n",
    "```\n",
    "\n",
    "Once you have completed the setup for one of these two environments, you are ready to start working with the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Search for SLC images over Haiti in a defined time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.strptime('2020-08-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "end_time = datetime.strptime('2021-08-16T23:59', '%Y-%m-%dT%H:%M')\n",
    "event_time = datetime.strptime('2021-08-14T00:00', '%Y-%m-%dT%H:%M')\n",
    "\n",
    "import asf_search\n",
    "scenes_to_submit = []\n",
    "wkt = 'POLYGON((-74.6 18.0,-73.0 18.0,-73.0 18.8,-74.6 18.8, -74.6 18.0))'\n",
    "results_descending = asf_search.geo_search(platform=[asf_search.PLATFORM.SENTINEL1], intersectsWith=wkt, processingLevel='SLC', start=start_time, end=end_time, relativeOrbit=142, frame=530)\n",
    "# [scenes_to_submit.append(result.properties['sceneName']) for result in results]\n",
    "# print(f'There are {len(scenes_to_submit)} scenes in the AOI between {start_time} and {end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "properties = [result.geojson()['properties'] for result in results_descending]\n",
    "geometries = [shape(result.geojson()['geometry']) for result in results_descending]\n",
    "gdf = gpd.GeoDataFrame(properties, geometry=geometries,crs='EPSG:4326')\n",
    "scenes_to_submit = list(gdf['sceneName'])\n",
    "print(gdf.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.explore(style_kwds=dict(color='black', fill=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_gdf = gdf[['sceneName', 'startTime']].copy()\n",
    "plot_gdf['startTime'] = pd.to_datetime(plot_gdf['startTime'])\n",
    "plot_gdf = plot_gdf.sort_values('startTime').reset_index()\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(7,7))\n",
    "ax.scatter(pd.to_datetime(plot_gdf['startTime']), plot_gdf.index, s=5)\n",
    "ax.set(xlabel='Date', ylabel='Image Number')\n",
    "ax.axvline(event_time, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Acquire Data using HyP3 SDK"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Submit jobs from Step 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "\n",
    "print(f'Submitting {len(scenes_to_submit)} jobs')\n",
    "hyp3 = sdk.HyP3()\n",
    "rtc_jobs = sdk.Batch()\n",
    "for scene in scenes_to_submit:\n",
    "    rtc_jobs += hyp3.submit_rtc_job(granule=scene, name='IGARSS-HAITI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir_path = 'haiti_rtcs'\n",
    "rtc_jobs = hyp3.watch(rtc_jobs)\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "file_list = succeeded_jobs.download_files(location=data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Download pre-processed data with the HyP3 SDK"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "hyp3 = sdk.HyP3()\n",
    "\n",
    "if not os.path.isdir('haiti_rtcs'):\n",
    "    os.mkdir('haiti_rtcs')\n",
    "rtc_jobs = hyp3.find_jobs(name='IGARSS-HAITI', user_id ='ffwilliams2')\n",
    "succeeded_jobs = rtc_jobs.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "file_list = succeeded_jobs.download_files(location='haiti_rtcs')\n",
    "\n",
    "files = Path('haiti_rtcs').glob('*')\n",
    "for file in files:\n",
    "    sdk.util.extract_zipped_product(file, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Crop all images to same extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def get_common_overlap(file_list: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the common overlap of  a list of GeoTIFF files\n",
    "    \n",
    "    Arg:\n",
    "        file_list: a list of GeoTIFF files\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], the upper-left x, upper-left y, lower-right x, and lower-right y\n",
    "         corner coordinates of the common overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in file_list]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "def clip_hyp3_products_to_common_overlap(data_dir: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all GeoTIFF files to their common overlap\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            directory containing the GeoTIFF files to clip\n",
    "        overlap:\n",
    "            a list of the upper-left x, upper-left y, lower-right-x, and lower-tight y\n",
    "            corner coordinates of the common overlap\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    files_for_mintpy = ['_VV.tif', '_VH.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "\n",
    "        for file in data_dir.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('haiti_rtcs')\n",
    "files = list(data_dir.glob('**/*_VV.tif'))\n",
    "overlap = get_common_overlap(files)\n",
    "clip_hyp3_products_to_common_overlap(data_dir, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the geotiffs into Xarray with datetime stamps for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess(da_orig, file_type: str='vv'):\n",
    "    '''function that should return an xarray object with time dimension and associated metadata given a path to a single RTC scene, if its dualpol will have multiple bands, currently just as 2 data arrays but could merge.\n",
    "    goal would be to apply this a list of directories for different RTC products, return cube along time dimension - I think?\n",
    "    - for concatenating, would need to check footprints and only take products with the same footprint, or subset them all to a common AOI? '''\n",
    "    da = da_orig.copy()\n",
    "    da = da.rename({'band_data': file_type}).squeeze()\n",
    "    fname = os.path.basename(da_orig['band_data'].encoding['source'])\n",
    "    time = datetime.strptime(fname[7:22], '%Y%m%dT%H%M%S')\n",
    "    da = da.assign_coords({'time': time})\n",
    "    da = da.expand_dims('time')\n",
    "    da = da.drop_duplicates(dim=['x', 'y'])\n",
    "\n",
    "    return da\n",
    "\n",
    "fpaths_vv = list(Path('haiti_rtcs').glob('*/*_VV_clipped.tif'))\n",
    "rtc_vv = xr.open_mfdataset(paths = fpaths_vv, preprocess = preprocess, chunks = 'auto', engine='rasterio', data_vars='minimal', coords='minimal', concat_dim='time', combine='nested', parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_vv['vv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Pre-temporal averaging, create time series plot of single pixel (or group of pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 6. Create a temporal average for both pre and post EQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.strptime('2020-08-01T23:59', '%Y-%m-%dT%H:%M')\n",
    "end_time = datetime.strptime('2021-08-16T23:59', '%Y-%m-%dT%H:%M')\n",
    "event_time = datetime.strptime('2021-08-14T00:00', '%Y-%m-%dT%H:%M')\n",
    "\n",
    "date_bins = [start_time, event_time, end_time]\n",
    "date_bin_labels = ['preevent', 'postevent']\n",
    "\n",
    "rtc_vv = rtc_vv.groupby_bins('time', date_bins, labels=date_bin_labels)\n",
    "mean_vv = rtc_vv.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vv['vv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 7. Perform a log difference of the two resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_diff =  10*np.log10(mean_vv['vv'][0]/mean_vv['vv'][1])\n",
    "log_diff = log_diff.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(log_diff)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 8. Discuss options for thresholding the difference image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 9. Use the COP30 DEM to remove change detections in areas with slopes <5 degrees use gdaldem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dem_stitcher import stitch_dem\n",
    "\n",
    "\n",
    "dem_file = data_dir_path / 'DEM.tif'\n",
    "bounds = [-74.6, 18.0, -73.0, 18.8]\n",
    "X, p = stitch_dem(bounds,\n",
    "                  dem_name='glo_30',  # Global Copernicus 30 meter resolution DEM\n",
    "                  dst_ellipsoidal_height=False,\n",
    "                  dst_area_or_point='Point')\n",
    "\n",
    "import rasterio\n",
    "\n",
    "with rasterio.open(dem_file, 'w', **p) as ds:\n",
    "   ds.write(X, 1)\n",
    "   ds.update_tags(AREA_OR_POINT='Point')\n",
    "\n",
    "process_dem_file = data_dir_path / 'DEM_processed.tif'\n",
    "gdal.DEMProcessing(destName=str(process_dem_file), srcDS=str(dem_file), processing=\"slope\", format=\"Gtiff\", slopeFormat=\"degree\")\n",
    "\n",
    "height, width = np.shape(log_diff)\n",
    "gdal.Warp(str(process_dem_file), str(process_dem_file), dstSRS='EPSG:4326',\n",
    "                  outputBounds=bounds, width=width, height=height, resampleAlg='nearest', format='GTiff')\n",
    "\n",
    "dem = gdal.Open(str(process_dem_file), gdal.GA_ReadOnly).ReadAsArray()\n",
    "dem_mask = dem > 5\n",
    "\n",
    "log_diff = log_diff.where(dem_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ### 10. Plot a histogram for the difference image (might have to subset histogram source to area with equal amounts of landslides and non-landslides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(log_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 11. Create a figure to interactively view the data and set a threshold using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(log_diff.where(dem_mask))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar_analysis [conda env:.local-insar_analysis]",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}