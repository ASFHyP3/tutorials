{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {},
   "source": [
    "# Mt. Edgecumbe volcanic InSAR time series analysis with HyP3 and MintPy\n",
    "\n",
    "In this notebook, you will learn how to perform a time series InSAR analysis using the popular Small BAseline Subset (SBAS) technique. SBAS is well suited for monitoring slow, consistent deformation of the earth's surface caused by processes such as slow landslides, subsidence, fault creep and volcanic inflation. In this tutorial we will focus on a volcanic inflation use case at [Mt. Edgecumbe, Alaska](https://en.wikipedia.org/wiki/Mount_Edgecumbe_(Alaska)).\n",
    "\n",
    "In April 2022, a seismic swarm near Mt. Edgecumbe in southeast Alaska suggested there be could be renewed activity at the volcano. However, since the last sign of activity at Mt. Edgecumbe was about 800 years ago, there was no monitoring equipment installed at the volcano. This made it difficult to determine if the volcano really was coming out of dormancy. Luckily, the team at the Alaska Volcano Observatory included experienced InSAR users, and they were able use a time series analysis to show that volcanic inflation had begun at the site in 2018. This analysis took much less time than more traditional methods, and was critical for providing timely information about the status of the volcano to the neighboring city of Sitka, Alaska.\n",
    "\n",
    "This notebook will show you how to perform the InSAR time series analysis that the AVO team used to reach their conclusions. It follows the methodology detailed in their recent paper [(Grapenthin et. al., 2022)](https://doi.org/10.1029/2022GL099464), which utilizes On Demand InSAR products from the Alaska Satellite Facility (ASF) and the MintPy time series analysis software. \n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1. Use the [HyP3 Python SDK](https://hyp3-docs.asf.alaska.edu/using/sdk/) to:\n",
    "   - Request On Demand InSAR products from ASF HyP3\n",
    "   - Download the InSAR products when they are done processing\n",
    "2. Use [MintPy](https://mintpy.readthedocs.io/en/latest/) and various Python utilities to:\n",
    "   - Download staged data that we will use for the time series (check out the `data_prep.py` script to see how the data was prepared)\n",
    "   - Assess the quality of the interferogram network we will use for the analysis\n",
    "   - Assess whether the data quality is suitable for a time series analysis\n",
    "   - Perform SBAS time series analyses for three InSAR stacks over Mt. Edgecumbe\n",
    "   - Demonstrate how to view the results of a time series analysis\n",
    "   - Discuss common \"gotchas\" that occur in time series analysis\n",
    "   - Reproduce the main InSAR figure from the AVO team's recent publication [(Figure 2 from Grapenthin et. al., 2022)](https://doi.org/10.1029/2022GL099464)\n",
    "---\n",
    "\n",
    "**Note:** This notebook uses staged data to ensure that there is adequate time to step through the InSAR time series workflow and discuss the analysis methods. It also assumes that you have some familiarity with InSAR processing already. If you're new to InSAR and working with ASF's on-demand services, you may find the following resources useful:\n",
    "1. our [InSAR on Demand Story Map](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "2. The `data_prep.py` script in the same directory as this notebook\n",
    "3. [OpenSARlab's](https://opensarlab-docs.asf.alaska.edu/) highly detailed walkthrough of preparing ASF on-demand (HyP3) data for MintPy via these notebooks:\n",
    "    - [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "    - [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "\n",
    "This notebook and the ones listed above assume that you're working in OpenSARlab. However, you can also run these \n",
    "notebooks outside of OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml) and launching these notebooks from within this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6e353",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need to be in the `insar_analysis` conda environment within OpenSARLab.\n",
    "\n",
    "Alternatively, you can set upon your own environment by running these commands in your shell:\n",
    "```shell\n",
    "curl -OL https://raw.githubusercontent.com/ASFOpenSARlab/opensarlab-envs/main/Environment_Configs/insar_analysis_env.yml\n",
    "conda env create -f insar_analysis_env.yml\n",
    "```\n",
    "Then launch this notebook from the new environment:\n",
    "```shell\n",
    "conda activate insar_analysis\n",
    "jupyter lab igarss_mtedgecumbe_ts_analysis.ipynb\n",
    "```\n",
    "\n",
    "Then we'll start the data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5b0b",
   "metadata": {},
   "source": [
    "## 1. Request On Demand InSAR products from ASF HyP3\n",
    "\n",
    "A major step towards working with SAR data at scale is learning how to download and request the creation of data programmatically. Accomplishing these tasks via code makes it much easier to request large amounts of data and to make similar requests in the future.\n",
    "\n",
    "To request the generation of an Interferometric Synthetic Aperture Radar (InSAR) product from the Alaska Satellite Facility (ASF), you can follow the general steps outline in the cells below. For this example, we'll be requesting the generation of an interferogram that shows inflation-related displacement at Mt. Edgecumbe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd24a07-2665-4bdc-83e0-bedc4f33c7fe",
   "metadata": {},
   "source": [
    "1. Create an account: If you haven't already, create an [NASA Earthdata login](https://urs.earthdata.nasa.gov/). This will allow you connect to ASF HyP3 via the Python SDK. Running the cell below will prompt you for Earthdata username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "hyp3 = sdk.HyP3(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387a5e2-f145-41b8-8cb8-f8d29155fff0",
   "metadata": {},
   "source": [
    "2. Select your data: Use ASF's [Vertex](https://search.asf.alaska.edu/) data search portal to find Sentinel-1 scenes your interesed in processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d2ebe-e14e-4998-a37e-f9b32d106902",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = 'S1B_IW_SLC__1SDV_20180628T151540_20180628T151607_011575_015476_4673'\n",
    "secondary = 'S1B_IW_SLC__1SDV_20190705T151547_20190705T151614_017000_01FFC4_D62F'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b4574-0bcd-4ce7-8bda-cc2bb95f17ee",
   "metadata": {},
   "source": [
    "3. Define your processing parameters: Determine the specific processing parameters for your InSAR product. This includes selecting the desired satellite data acquisitions, multilook, and whether to apply a water mask before unwrapping. You can read more about the available parameters within the [HyP3 SDK documentation](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_insar_job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa37d6-ec58-4209-bd7d-43b42fd3c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "looks='20x4'\n",
    "include_dem=True\n",
    "include_look_vectors=True\n",
    "apply_water_mask=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427de656-ef70-45d1-b0be-ee63375182ad",
   "metadata": {},
   "source": [
    "4. Submit a processing request: Once you have defined your parameters, use the HyP3 SDK's [`submit_insar_job`](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.submit_insar_job) function to submit a processing request. You can use the `project_name` name argument to group sets of requests together under one name so that you can easily look them up later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9930b-1999-4415-a448-a2bbf586a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "project_name = 'edgecumbe_example'\n",
    "jobs = sdk.Batch()\n",
    "jobs += hyp3.submit_insar_job(reference, secondary, name=project_name, \n",
    "                              looks=looks, include_dem=include_dem, include_look_vectors=include_look_vectors, apply_water_mask=apply_water_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d74f02-1225-47ce-bdcc-5a150d16fec3",
   "metadata": {},
   "source": [
    "5. Monitor the processing status: After submitting your request, the ASF HyP3 will process your data and generate the InSAR product. You can usually monitor the processing by calling the [`watch`](https://hyp3-docs.asf.alaska.edu/using/sdk_api/#hyp3_sdk.hyp3.HyP3.watch) HyP3 SDK method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b82d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.watch(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c01d37-7dd6-44f9-b73a-b51bb252dd2c",
   "metadata": {},
   "source": [
    "6. Access and download the InSAR product: Once the processing is complete, your InSAR job status will be updated to `SUCCEEDED` and your data will be ready to download. You can download the data by searching for jobs with teh `SUCCEEDED` status that also have your project name..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.find_jobs(name=project_name, status_code = 'SUCCEEDED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44506c24-1562-4e2b-87ea-a68bb1c25cb2",
   "metadata": {},
   "source": [
    "...then using the `download_files` method to download the data. There is also functionality in the HyP3 SDK that you can use to unzip the files as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b461cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "insar_products = jobs.download_files('.')\n",
    "insar_products = [sdk.util.extract_zipped_product(ii) for ii in insar_products]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad79f1c-96ec-4f99-ae77-328eb07a11d7",
   "metadata": {},
   "source": [
    "Now that we've gone through the work of requesting and downloading the interferogram, let's take a look at it. Here we plot the unwrapped interferogram overlayed on top of the DEM used for processing. This interferogram shows the inflation deformation signal that Grapenthin et. al. origionally discovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b21301-3ec9-46b2-87fb-3563ba7e66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unwrapped_file = 'S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722/S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722_unw_phase.tif'\n",
    "amp_file = 'S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722/S1BB_20180628T151540_20190705T151547_VVP372_INT80_G_weF_A722_amp.tif'\n",
    "\n",
    "ds = gdal.Open(unwrapped_file)\n",
    "unwrapped = np.ma.masked_equal(ds.GetRasterBand(1).ReadAsArray(), 0)\n",
    "del ds\n",
    "\n",
    "ds = gdal.Open(amp_file)\n",
    "amp = np.ma.masked_equal(ds.GetRasterBand(1).ReadAsArray(), 0)\n",
    "del ds\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "ax.imshow(unwrapped[1250:1575, 700:1000], alpha=0.75, cmap='jet')\n",
    "ax.imshow(amp[1250:1575, 700:1000], alpha=0.4, cmap='Greys', norm=matplotlib.colors.LogNorm())\n",
    "ax.set_title('Unwrapped Interferogram')\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17efa6-3371-425a-bcb9-49cafece2bb6",
   "metadata": {},
   "source": [
    "This section walked you through requesting and downloading one interferogram, but time series InSAR routinely make use of hundreds of interferograms (Grapenthin et. al., 2022 used XX!). Unfortunately we don't have the time to request and download this many interferograms during this workshop, so instead we've pre-generated and prepped some InSAR for you to work with. Think of it as your very own InSAR cooking show!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181031f",
   "metadata": {},
   "source": [
    "## 3. Time-series Analysis with MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdc929-1c7a-473b-93d3-0b304072a8df",
   "metadata": {},
   "source": [
    "### 3.1 Download the Staged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7828894-2c7f-479e-82ae-c54f3638830e",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are getting pair lists from the [supplementary information](https://zenodo.org/record/7151431) published by Grapenthin et. al.. Take a look at the `prep_data.py` script in the same directory as this notebook to see how we're doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74467d63-2961-4d64-b9e8-dfadd6875ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "files = ['ascending_50.zip', 'ascending_79.zip', 'descending_174.zip', 'descending_174_nomask.zip']\n",
    "\n",
    "for file in files:\n",
    "    download_path = Path(file)\n",
    "    s3_client.download_file('ffwilliams2-shenanigans', f'igarss_2023/{file}', download_path)\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(download_path.stem)\n",
    "    os.unlink(download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1eb17-d324-40cf-b276-119defcda838",
   "metadata": {},
   "source": [
    "### 3.2 MintPy Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd69717-b132-42a7-a7f1-3d77a8b2ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df6393-ce66-445c-bf63-5cd5620c9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat descending_174/mintpy_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8546c7c-c9e1-47e7-91e7-446b0ef58e63",
   "metadata": {},
   "source": [
    "### 3.3 Run MintPy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9b16a-f0d1-4594-b1c6-7a9c56abe601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you run MintPy for all four stacks\n",
    "stacks = ['ascending_50', 'ascending_79', 'descending_174', 'descending_174_nomask']\n",
    "stack = stacks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aaf24-7662-4928-af7a-fcaecdd93dde",
   "metadata": {},
   "source": [
    "#### 3.3.1 Check Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcfe7b-951e-448e-8fa0-1f807712d9b7",
   "metadata": {},
   "source": [
    "In snowy areas like Mt. Edgecumbe, the use of a normal Small Baseline Subset (SBAS) network for Interferometric Synthetic Aperture Radar (InSAR) analysis may encounter certain limitations, particularly during the winter season. The presence of snow on the ground introduces significant decorrelation effects that hinder the accurate measurement of surface displacements. As a result, interferograms generated during winter periods tend to be unreliable and less informative. To overcome this challenge, it becomes necessary to exclude interferograms from the winter season. However, excluding winter interferograms leaves a data gap that can hamper the continuity of monitoring. To address this issue, an alternative approach is to create longer baseline interferograms, which span over a longer period of time and cover the missing winter period. By extending the baseline length, it becomes possible to capture a larger temporal span, allowing for a more comprehensive analysis of surface deformation, despite the limitations imposed by the snowy conditions. See the graph below to see the network that Grapenthin et. al. used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d0a40-351a-40d5-8fe0-15d8c83e64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.collections import LineCollection\n",
    "from mintpy.utils.network import get_date12_list\n",
    "\n",
    "pair_list = pd.DataFrame([pair.split('_') for pair in get_date12_list(f'{stack}/inputs/ifgramStack.h5')], columns=['date1', 'date2'])\n",
    "pair_list['date1'] = pd.to_datetime(pair_list['date1'])\n",
    "pair_list['date2'] = pd.to_datetime(pair_list['date2'])\n",
    "\n",
    "# subplot 1 data\n",
    "lines = []\n",
    "bridges = []\n",
    "for i, row in pair_list.iterrows():\n",
    "    point1 = [mdates.date2num(row['date1']), i]\n",
    "    point2 = [mdates.date2num(row['date2']), i]\n",
    "    if point2[0] - point1[0] > 48:\n",
    "        bridges.append([point1, point2])\n",
    "    else:\n",
    "        lines.append([point1, point2])\n",
    "\n",
    "# subplot 2 data\n",
    "date1_number = mdates.date2num(pair_list.date1)\n",
    "date2_number = mdates.date2num(pair_list.date2)\n",
    "dates = np.concatenate((date1_number, date2_number))\n",
    "min_date = np.min(dates)\n",
    "max_date = np.max(dates)\n",
    "\n",
    "date_range = np.arange(np.min(dates), np.max(dates))\n",
    "coverage = np.zeros(int(np.max(dates) - np.min(dates)))\n",
    "for ifg_date1, ifg_date2 in zip(date1_number, date2_number):\n",
    "    ifg_coverage = np.arange(ifg_date1 - min_date, ifg_date2 - min_date, dtype=int)\n",
    "    coverage[ifg_coverage] += 1\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "line_segments = LineCollection(lines, array=range(len(lines)), linewidths=1, cmap='gist_rainbow', label='Interferograms')\n",
    "bridge_segments = LineCollection(bridges, color='black', linestyle='dashed', linewidths=1, label='Bridging Interferograms')\n",
    "ax1.add_collection(line_segments)\n",
    "ax1.add_collection(bridge_segments)\n",
    "ax1.set(\n",
    "    ylabel='Interferogram Number',\n",
    "    xlabel='Date',\n",
    "    xlim=(mdates.date2num(np.min(pair_list['date1'])) - 10, mdates.date2num(np.max(pair_list['date2'])) + 10),\n",
    "    ylim=(-1, pair_list.shape[0] + 1),\n",
    ")\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2.plot(date_range, coverage, color='black', linewidth=2)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "ax2.set(xlabel='Date', ylabel='# of interferograms covering date', ylim=(0, np.max(coverage) + 1))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e756304-f75b-4430-8d8e-988f56070fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --dostep modify_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e77538-bd5d-40de-b2a4-d10c3f7b5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import plot_network\n",
    "\n",
    "plot_network.main(f'{stack}/inputs/ifgramStack.h5 --figsize 12 3'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738761b-e5cf-43ac-aad4-0a4094c07762",
   "metadata": {},
   "source": [
    "#### 3.3.2 Check Reference Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245b6c8-16ec-4000-b516-3aea7379edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --dostep reference_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e45402-23fe-4d68-8fc2-5b2c0821ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import view\n",
    "\n",
    "cfg = readfile.read_template(f'{stack}/smallbaselineApp.cfg')\n",
    "ref_la, ref_lo = [int(coord) for coord in cfg['mintpy.reference.lalo'].strip(\"[]\").split(', ')]\n",
    "view.main(f'{stack}/avgSpatialCoh.h5 --pts-lalo {ref_la} {ref_lo} --noverbose --figsize 8 8'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7ca34-ba99-4e2f-82e4-8535b1c1e24e",
   "metadata": {},
   "source": [
    "#### 3.3.3 Estimate Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33793550-0d53-40e8-9fd1-bced203da9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir $stack $stack/mintpy_config.txt --start quick_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff4fd0-c326-407c-919b-c29f5dbb1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import tsview\n",
    "\n",
    "cmd = f'{stack}/timeseries_ERA5_demErr.h5 --figsize 9 3 --noverbose'\n",
    "tsview.main(cmd.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e83b0-7128-45af-bf54-7c1d325dd148",
   "metadata": {},
   "source": [
    "**Have you run MintPy for all four stacks!?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac85337-6096-412b-bfa6-a7616c67f9d6",
   "metadata": {},
   "source": [
    "## 4. Data Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa45e3-72e4-4ca5-9705-05409f90b8dc",
   "metadata": {},
   "source": [
    "**Make sure you've run MintPy for all four stacks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a657df-0ac4-44f1-8af0-8b28adc53641",
   "metadata": {},
   "source": [
    "### 4.1 Effect of Water Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647b87c-aca7-4319-9165-a9965d5eaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mintpy.utils import readfile\n",
    "\n",
    "velocity_nomask, _ = readfile.read('descending_174_nomask/velocity.h5')\n",
    "velocity_nomask = np.ma.masked_equal(velocity_nomask,0)\n",
    "\n",
    "velocity_mask, _ = readfile.read('descending_174/velocity.h5')\n",
    "velocity_mask = np.ma.masked_equal(velocity_mask,0)\n",
    "\n",
    "difference = velocity_mask - velocity_nomask\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 6))\n",
    "ax1.imshow(velocity_mask, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax1.set(title='Water Masked')\n",
    "ax2.imshow(velocity_nomask, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax2.set(title='Not Water Masked')\n",
    "diff_plot = ax3.imshow(difference, cmap='jet', norm=colors.CenteredNorm(halfrange=np.std(difference)))\n",
    "ax3.set(title='Water Masked - Not Water Masked')\n",
    "\n",
    "cax = ax3.inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "f.colorbar(diff_plot, ax=ax3, cax=cax)\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00f602-b2b5-41c8-a78c-59991ffa552d",
   "metadata": {},
   "source": [
    "### 4.2 Final Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e3180-c306-4bfd-88c2-2639657440ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mintpy.utils import readfile\n",
    "\n",
    "ascending_50, _ = readfile.read('ascending_50/velocity.h5')\n",
    "ascending_50 = np.ma.masked_equal(ascending_50, 0)\n",
    "\n",
    "ascending_79, _ = readfile.read('ascending_79/velocity.h5')\n",
    "ascending_79 = np.ma.masked_equal(ascending_79, 0)\n",
    "\n",
    "descending_174, _ = readfile.read('descending_174/velocity.h5')\n",
    "descending_174 = np.ma.masked_equal(descending_174, 0)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 6))\n",
    "ax1.imshow(ascending_79, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax1.set(title='Ascending 79')\n",
    "ax2.imshow(ascending_50, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax2.set(title='Ascending 50')\n",
    "cbar_plot = ax3.imshow(descending_174, cmap='jet', vmin=-0.04, vmax=0.07)\n",
    "ax3.set(title='Descending 174')\n",
    "\n",
    "cax = ax3.inset_axes([1.05, 0.25, 0.05, 0.5])\n",
    "f.colorbar(cbar_plot, ax=ax3, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940fa07-655a-4ac9-819e-f7d8c7d93c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
